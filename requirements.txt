はい、追加A（仮想マイク方式）を基本線にして、既存の「ヘッドホンで聴く変換（Listening Mode）」と統合した macOS向け統合版のシステム要件（完全版） を作成します。
macOSで仮想デバイス（仮想マイク/仮想スピーカー）を作る中核は Core Audio の Audio Server Driver Plug-in で、これにより仮想オーディオデバイスを実装できます。 ￼
（補足：AudioDriverKit は主に物理デバイス向けで、仮想デバイスだけが目的なら Audio Server plug-in モデルが継続推奨という趣旨の議論もあります。 ￼）

⸻

統合版システム要件定義書（macOS）

リアルタイム音声変換：Listening + Speaking（仮想マイク方式）

0. 文書情報
	•	対象：macOS向けデスクトップアプリ + CoreAudio仮想デバイス
	•	対応アプリ：Google Meet / Zoom / Teams（基本は「マイク入力デバイスを選べる」アプリ全般）
	•	目的：
	•	Listening Mode：相手の声やPC音声を“自分のヘッドホンへ”変換して聴く
	•	Speaking Mode：自分の声を変換し“相手へ（会議アプリへ）”送る（仮想マイク）

⸻

1. ゴールとスコープ

1.1 ゴール
	•	Aユーザーがヘッドホン装着時に、以下を低遅延でリアルタイム変換できること。
	1.	聴く：会議相手の音声（システム音）→変換→ヘッドホンへ
	2.	話す：マイク音声→変換→仮想マイク→会議アプリへ

1.2 非ゴール
	•	会議アプリ（Meet等）の拡張機能としてブラウザ内部で完結させる（今回は採用しない）
	•	YouTube等のURLから無制限に音声を取得して学習する（権利/規約の観点で設計対象外）

⸻

2. 全体アーキテクチャ

2.1 構成要素
	1.	Desktop App（UI/制御）
	•	Mode切替、プリセット選択、デバイス選択、レイテンシ調整、学習・登録フロー
	2.	Audio Engine（DSP/AI）
	•	低遅延音声処理パイプライン（DSP + オプションで軽量ニューラル）
	3.	Virtual Audio Device（Core Audio Audio Server Driver Plug-in）
	•	仮想マイク（Input）
	•	仮想スピーカー（Output）
	•	ルーティング（仮想Output→処理→仮想Input など） ￼
	4.	Audio Routing / Helper（権限・自動切替・バックグラウンド常駐）
	•	既定入出力の切替補助、デバイス監視、落ちたときの復旧

参考：オープンソースでも「Audio Server plug-in + helper app」で仮想デバイスを作り、出力→処理→入力へ回す構成例があります。 ￼

⸻

3. ユーザーフロー要件

3.1 初回セットアップ
	•	(1) インストール（App + 仮想オーディオデバイス）
	•	(2) マイク/ヘッドホンの権限許可（macOSのマイク権限）
	•	(3) 入力/出力デバイスの初期設定
	•	(4) テスト（ループバックで遅延・音切れチェック）

3.2 通常利用（会議前）
	•	Aユーザーはアプリを起動し、以下を選ぶだけで使えること：
	•	Listening：ON/OFF
	•	Speaking：ON/OFF
	•	プリセット（Listen用 / Speak用）
	•	低遅延モード（Ultra Low / Balanced / High Quality）

3.3 会議アプリ側の設定（Google Meet）
	•	マイク：本アプリの仮想マイクを選択
	•	スピーカー：通常どおり（ヘッドホン）
	•	※Listening Modeを「システム音変換」でやる場合、会議アプリの出力先を仮想スピーカーにする運用も可能（後述）

⸻

4. 機能要件（Functional Requirements）

4.1 Listening Mode（聴く変換）

入力ソース（どちらか、または両方）
	•	L1：システム音（会議相手の音声・PC音声）
	•	L2：外部マイク（周囲の音）

出力
	•	ヘッドホン（物理デバイス）へ

変換機能
	•	EQ / コンプレッサ / ノイズ抑制
	•	ピッチ/フォルマント（軽量）
	•	（任意）軽量ニューラルVC（GPUがある場合のみON推奨）

4.2 Speaking Mode（話す変換：仮想マイク）

入力
	•	物理マイク（内蔵/外付け）

出力
	•	仮想マイク（Core Audio仮想入力デバイス） ￼

変換機能
	•	ノイズ抑制（会議用途）
	•	自動ゲイン（AGC）
	•	エコー抑制（後述のAEC設計とセット）
	•	ボイスプリセット（男性→女性、落ち着いた声、キャラ声 等）

4.3 デバイス自動切替（任意だが強く推奨）
	•	「会議開始」検知までは必須にしないが、
	•	ヘッドホン接続時にListening ON提案
	•	会議アプリ起動時にSpeaking ON提案
	•	既定デバイス復帰（終了時）
を提供するとUXが劇的に良くなる。

4.4 プリセット管理
	•	Listenプリセットと Speakプリセットを別管理（混同しない）
	•	エクスポート/インポート（社内展開、複数端末対応）

4.5 追加音声（カスタム）登録

4.5.1 登録方式（要件）
	•	基本：音声ファイル（WAV/MP3）アップロード
	•	収録ガイド：5分（簡易）/ 30分（高品質）
	•	自動前処理：無音除去・正規化・ノイズ推定・VAD

4.5.2 YouTube URL（オプション要件）
	•	「URLを貼るだけで自動生成」は要件化する場合でも制限付き：
	•	ユーザーが権利を持つコンテンツのみ
	•	同意チェック/ログ記録
	•	仕様として「規約回避・不正取得」を目的にしない（コンプラ要件）
（※ここは法務・運用ポリシーの章にも必ず明記）

⸻

5. レイテンシ要件（超重要）

5.1 目標値
	•	Listening：端末内処理 40ms以下目標
	•	Speaking：端末内処理 50ms以下目標（会議側WebRTCで追加遅延が乗るため）

5.2 設定項目
	•	サンプルレート：48kHz（会議用途標準に合わせる）
	•	バッファ：64/128/256サンプル（段階選択）
	•	“Ultra Low”ではエフェクト数を自動制限

⸻

6. 音響事故を避ける設計（AEC/ハウリング対策）

6.1 問題

Listeningで出した音がマイクに回り込み、Speakingへ混入すると
	•	エコー
	•	ハウリング
	•	二重音声
が発生しやすい。

6.2 必須対策（要件）
	•	イヤホン/ヘッドホン前提（スピーカー利用は警告）
	•	AEC（Acoustic Echo Cancellation）をSpeaking側に実装
	•	マイク入力から「仮想スピーカー出力」の参照信号を取り、キャンセル計算に渡す
	•	“安全モード”：
	•	AECが効かない環境ではSpeaking ON時にListeningを自動OFFまたは弱める

⸻

7. macOS実装要件（仮想オーディオ）

7.1 仮想デバイス方式
	•	Core Audioの Audio Server Driver Plug-in により仮想オーディオデバイスを作る。 ￼
	•	役割：
	•	仮想マイク（会議アプリが選択する入力）
	•	仮想スピーカー（システム音を取り込むための出力先にできる）

7.2 インストール/配布要件
	•	仮想デバイスの導入がユーザーにとって分かりやすい導線
	•	OSのセキュリティ警告・権限（マイク等）を最小の手数でクリアできるUX
	•	アンインストール時に仮想デバイスも確実に除去

⸻

8. 非機能要件

8.1 安定性
	•	2時間連続会議で音切れなし
	•	スリープ復帰後も復旧
	•	デバイス抜き差しでクラッシュしない

8.2 セキュリティ/プライバシー
	•	デフォルト：音声処理は端末内（ローカル）
	•	カスタム音声モデルは暗号化して保存
	•	ログに生音声は保存しない（メタ情報のみ）

8.3 パフォーマンス
	•	CPU使用率上限（目標）：
	•	Ultra Low：片系（Listening or Speaking）で 10〜15%以内（目安、機種差あり）
	•	バッファ不足時は自動で品質を下げてでも音切れ回避

⸻

9. 検証仕様（Acceptance / Test）

9.1 機能テスト
	•	Listening ON/OFF 即時切替（クリック音無し）
	•	Speaking ON/OFF 即時切替（会議アプリに音声が届く/止まる）
	•	プリセット変更時の無音時間：100ms以下

9.2 レイテンシ測定
	•	ループバック計測（クリック音→ヘッドホン）
	•	目標を満たす設定のプリセット化（推奨設定）

9.3 会議アプリ互換
	•	Google Meet（Chrome / Safari）
	•	Zoom（クライアント）
	•	Teams（クライアント/ブラウザ）
	•	それぞれで「仮想マイクが選べる」「音が途切れない」を確認

9.4 事故系テスト
	•	ヘッドホンを抜く→安全停止
	•	Bluetooth遅延が大きい→警告表示
	•	AEC無効環境→自動でListening弱化 or Speak停止

⸻

10. MVP（最小構成）提案（macOS）

MVP v1
	•	Speaking Mode（仮想マイク）を先に安定化
	•	Listening Modeは「マイク入力（周囲音）」から開始（システム音取り込みは次）

v1.5
	•	仮想スピーカーを追加し、会議音（システム音）も変換対象へ

v2
	•	軽量ニューラルVC、カスタム音声登録を強化

（※この順が、macOSでの“詰まりどころ”を最も回避しやすいです）

⸻

11. 追加：開発タスク分解（そのままJiraに切れる粒度）
	•	AudioServerPlugIn：仮想マイク作成
	•	AudioServerPlugIn：仮想スピーカー作成（後半）
	•	Audio Engine：DSPチェーン（EQ/NS/AGC/AEC）
	•	UI：2トグル（Listen/Speak）+ デバイス選択 + 遅延モード
	•	Helper：デバイス監視・復旧・ログ
	•	Test Harness：レイテンシ計測ユーティリティ

⸻

必要なら、この要件をさらに 「開発AIに投げるSRS形式」（用語集、ユースケース図、状態遷移、エラーハンドリング、受入基準を細分化）に整形して、完全に実装指示書として成立する形まで一気に整えます。
このまま続けて、次は MVPを v1（Speaking中心）で確定して、各モジュールの「入出力IF」と「スレッド/バッファ設計」まで書き起こします。
